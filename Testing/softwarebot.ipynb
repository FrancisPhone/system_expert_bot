{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c0c5e26",
   "metadata": {},
   "source": [
    "Parse SQL Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f02e67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Schema: {' ': ['user_id', 'education_id', 'graduation_date', 'degree', \"'Bachelor'\", \"'Master'\", \"'PhD'\", \"'Diploma')\", 'specialization', 'createdAt', 'updatedAt'], 'TABLE': ['project_id', 'user_id', 'hours', 'user_role', \"'Member')\", 'user_contribution', 'createdAt', 'updatedAt']}\n",
      "Tables in Query: ['customers']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "import re\n",
    "\n",
    "def extract_tables_from_query(query):\n",
    "    parsed = sqlparse.parse(query)[0]\n",
    "    tables = []\n",
    "    for token in parsed.tokens:\n",
    "        if token.ttype is None and token.get_real_name():\n",
    "            tables.append(token.get_real_name())\n",
    "    return list(set(tables))\n",
    "\n",
    "def parse_schema_file(schema_file_path):\n",
    "    with open(schema_file_path, 'r') as f:\n",
    "        schema_sql = f.read()\n",
    "\n",
    "    tables = {}\n",
    "    for statement in sqlparse.parse(schema_sql):\n",
    "        if statement.get_type() == 'CREATE':\n",
    "            table_name = str(statement.tokens[4])\n",
    "            columns = []\n",
    "            inside_parens = str(statement).split('(', 1)[1].rsplit(')', 1)[0]\n",
    "            for line in inside_parens.split(','):\n",
    "                col = line.strip().split()[0]\n",
    "                if col.upper() not in ['PRIMARY', 'FOREIGN', 'CONSTRAINT']:\n",
    "                    columns.append(col)\n",
    "            tables[table_name] = columns\n",
    "    return tables\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"SELECT name, email FROM customers WHERE customer_id IN (SELECT customer_id FROM orders WHERE amount > 100);\"\n",
    "    schema = parse_schema_file(\"sample_schema.sql\")\n",
    "    print(\"Parsed Schema:\", schema)\n",
    "    print(\"Tables in Query:\", extract_tables_from_query(query))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36b151",
   "metadata": {},
   "source": [
    "SQL to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19867d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This query retrieves U.full_name AS Full_name, \n",
      "    U.email AS Email, \n",
      "    UE.degree AS Degree, \n",
      "    E.university_name AS University, \n",
      "    YEAR(UE.graduation_date) AS Graduation_year, \n",
      "    UE.specialization AS Specialization from the 'User' table\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def explain_sql(query):\n",
    "    parsed = sqlparse.parse(query)[0]\n",
    "    tokens = [token for token in parsed.tokens if not token.is_whitespace]\n",
    "\n",
    "    explanation = []\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.ttype is None and token.get_real_name():\n",
    "            continue\n",
    "        if token.ttype is sqlparse.tokens.DML and token.value.upper() == \"SELECT\":\n",
    "            explanation.append(\"This query retrieves\")\n",
    "            columns = str(tokens[i+1]).strip()\n",
    "            explanation.append(columns)\n",
    "        elif token.ttype is sqlparse.tokens.Keyword and token.value.upper() == \"FROM\":\n",
    "            table = str(tokens[i+1]).strip()\n",
    "            explanation.append(f\"from the '{table}' table\")\n",
    "        elif token.ttype is sqlparse.tokens.Keyword and token.value.upper() == \"WHERE\":\n",
    "            condition = str(tokens[i+1]).strip()\n",
    "            explanation.append(f\"where the condition '{condition}' is met\")\n",
    "\n",
    "    return \" \".join(explanation)\n",
    "\n",
    "# Example\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "    U.full_name AS Full_name, \n",
    "    U.email AS Email, \n",
    "    UE.degree AS Degree, \n",
    "    E.university_name AS University, \n",
    "    YEAR(UE.graduation_date) AS Graduation_year, \n",
    "    UE.specialization AS Specialization\n",
    "FROM User U\n",
    "JOIN User_Education UE ON U.id = UE.user_id\n",
    "JOIN Education E ON UE.education_id = E.id\n",
    "WHERE UE.specialization LIKE 'DSAI%';\n",
    "    \"\"\"\n",
    "    print(explain_sql(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b55b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AIT_lecture\\NLP\\pythonNLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "from transformers import pipeline\n",
    "\n",
    "class SQLExplainer:\n",
    "    def __init__(self, use_llm=False):\n",
    "        self.use_llm = use_llm\n",
    "        if use_llm:\n",
    "            self.generator = pipeline(\"text2text-generation\", model=\"t5-small\")\n",
    "\n",
    "    def template_explain(self, query):\n",
    "        parsed = sqlparse.parse(query)[0]\n",
    "        tokens = [token for token in parsed.tokens if not token.is_whitespace]\n",
    "\n",
    "        explanation = []\n",
    "\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token.ttype is None and token.get_real_name():\n",
    "                continue\n",
    "            if token.ttype is sqlparse.tokens.DML and token.value.upper() == \"SELECT\":\n",
    "                explanation.append(\"This query retrieves\")\n",
    "                columns = str(tokens[i+1]).strip().replace(\"\\n\", \" \")\n",
    "                explanation.append(columns)\n",
    "            elif token.ttype is sqlparse.tokens.Keyword and token.value.upper() == \"FROM\":\n",
    "                table = str(tokens[i+1]).strip()\n",
    "                explanation.append(f\"from the '{table}' table\")\n",
    "            elif token.ttype is sqlparse.tokens.Keyword and token.value.upper() == \"WHERE\":\n",
    "                condition = str(tokens[i+1]).strip().replace(\"\\n\", \" \")\n",
    "                explanation.append(f\"where the condition '{condition}' is met\")\n",
    "\n",
    "        return \" \".join(explanation)\n",
    "\n",
    "    def llm_explain(self, query):\n",
    "        prompt = f\"Explain this SQL query in simple English:\\n{query}\"\n",
    "        result = self.generator(prompt, max_length=100, do_sample=False)[0]['generated_text']\n",
    "        return result\n",
    "\n",
    "    def explain(self, query):\n",
    "        if self.use_llm:\n",
    "            return self.llm_explain(query)\n",
    "        else:\n",
    "            return self.template_explain(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "170bd4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text2text-generation\", model=\"t5-small\")\n",
    "\n",
    "def llm_explain(query):\n",
    "    prompt = f\"Explain this SQL query in simple English:\\n{query}\"\n",
    "    result = generator(prompt, max_length=100, do_sample=False)[0]['generated_text']\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71e0e2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Template Explanation ===\n",
      "This query retrieves U.full_name AS Full_name,      U.email AS Email,      UE.degree AS Degree,      E.university_name AS University,      YEAR(UE.graduation_date) AS Graduation_year,      UE.specialization AS Specialization from the 'User' table\n",
      "\n",
      "=== LLM Explanation ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT U.full_name AS Full_name, U.email AS Email, UE.degree AS Degree, E.university_name AS University, YEAR(UE.graduation_date) AS Graduation_year, UE.specialization AS Specialization FROM User U JOIN User_Education UE ON U.id = UE.user_id JOIN User_Education UE ON\n"
     ]
    }
   ],
   "source": [
    "from explain_sql import SQLExplainer\n",
    "\n",
    "# Sample Query\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    U.full_name AS Full_name, \n",
    "    U.email AS Email, \n",
    "    UE.degree AS Degree, \n",
    "    E.university_name AS University, \n",
    "    YEAR(UE.graduation_date) AS Graduation_year, \n",
    "    UE.specialization AS Specialization\n",
    "FROM User U\n",
    "JOIN User_Education UE ON U.id = UE.user_id\n",
    "JOIN Education E ON UE.education_id = E.id\n",
    "WHERE UE.specialization LIKE 'DSAI%';\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Template Explanation ===\")\n",
    "    explainer = SQLExplainer(use_llm=False)\n",
    "    print(explainer.explain(query))\n",
    "\n",
    "    print(\"\\n=== LLM Explanation ===\")\n",
    "    llm_explainer = SQLExplainer(use_llm=True)\n",
    "    print(llm_explainer.explain(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b7590d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": SQL Query: SELECT U.full_name AS Full_name, U.email AS Email, UE.degree AS Degree, E.university_name AS University, YEAR(UE.graduation_date) AS Graduation_year, UE.specialization AS Specialization FROM User U JOIN User_Education UE ON U.id = UE.user_id JOIN Education E ON UE.education_id = E.id\n"
     ]
    }
   ],
   "source": [
    "from rag_engine import RAGEngine\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    U.full_name AS Full_name, \n",
    "    U.email AS Email, \n",
    "    UE.degree AS Degree, \n",
    "    E.university_name AS University, \n",
    "    YEAR(UE.graduation_date) AS Graduation_year, \n",
    "    UE.specialization AS Specialization\n",
    "FROM User U\n",
    "JOIN User_Education UE ON U.id = UE.user_id\n",
    "JOIN Education E ON UE.education_id = E.id\n",
    "WHERE UE.specialization LIKE 'DSAI%';\n",
    "\"\"\"\n",
    "\n",
    "engine = RAGEngine(\"sample_schema.sql\", use_llm=True)\n",
    "print(engine.generate_documentation(sql_query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb6b14c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2728 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'KEY (user_id) REFERENCES User (id) ON DELETE CASCADE ON UPDATE CASCADE, FOREIGN KEY (user_id) REFERENCES Project (id) ON DELETE CASCADE ON UPDATE CASCADE, FOREIGN KEY (user_id) REFERENCES Group (id) ON DELETE CASCADE, FOREIGN KEY (user_'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag = RAGEngine(\"sample_schema.sql\", use_llm=True)\n",
    "rag.generate_documentation(sql_query)\n",
    "rag.answer_nl_question(\"How does the linkedNetwork Expert  work?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a74eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonNLP",
   "language": "python",
   "name": "pythonnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
